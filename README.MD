# Парсер данных с сайта госзакупок
В парсере использована библиотека Celery для постановки асинхронных задач в очередь.

# Назначение файлов:
main.py  - просто парсер, который извлекает нужные данные с сайта. Используется библиотека requests и BeautifulSoup
maincelery.py    - тот же парсер, но с использованием библиотеки Celery. В пару к нему идет файл tasks.py с задачами.

# Шпаргалка для запуска:
1. Необходимо устоновить Redis
2. Необходимо устоновить библиотеки: requests, BeautifulSoup, rediws, celery
3. Необходимо запустить воркер  
Запустить консоль и перейти в папку с проектом.  
Активировать виртуальную среду.  
Стандартная команда запуска воркера:  
celery -A tasks worker --loglevel=info  

Примечание:  
В windows стандартная команда для запуска воркера не работает.   
Нужно запускать один из вариантов команды:  

celery -A tasks worker --loglevel=info --pool=solo  
эта команда подходит под тяжелые задачи  
или  
celery -A tasks worker --loglevel=info --pool=threads --concurrency=8  
эта команда подходит под задачи с вводом выводом  